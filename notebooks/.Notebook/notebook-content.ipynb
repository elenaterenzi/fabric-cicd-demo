{"nbformat":4,"nbformat_minor":5,"cells":[{"cell_type":"markdown","source":["# City Safety Data - ETL - Sample"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"eeda8435-14f2-4a8e-96fa-3d396c7e48b3"},{"cell_type":"markdown","source":["## About this Notebook\n","\n","- This notebook performs a sample ETL operation using Microsoft Open datasets (city safety data).\n","- It **doesn't require** a default lakehouse attached and instead uses absolute paths to create/load managed tables.\n","- Can be run from any Fabric workspace as long as proper access to provided to write to the targets(workspace and lakehouse).\n","- Data can be loaded:\n","    - into a new table \n","    - into an existing table in append mode  (by setting - cleanup = False)\n","    - into an existing table in overwrite mode (by setting - cleanup = True)"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c79df08e-52c4-41b8-bd25-5bb4d3d4e6d7"},{"cell_type":"markdown","source":["## Libraries"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"1f72ca89-dae6-4fb2-9cd5-bc44b2e67207"},{"cell_type":"code","source":["import json\n","from pyspark.sql.functions import lit, to_utc_timestamp, unix_timestamp, avg, max, min, sum, count\n","from delta.tables import DeltaTable\n","from typing import Optional"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":[],"state":"cancelled","livy_statement_state":null,"session_id":null,"normalized_state":"cancelled","queued_time":"2025-04-02T14:32:13.7853472Z","session_start_time":"2025-04-02T14:32:13.7863288Z","execution_start_time":null,"execution_finish_time":"2025-04-02T14:32:50.0557977Z","parent_msg_id":"71b9e929-7b5a-42c5-87c7-11e50c2b27c7"},"text/plain":"StatementMeta(, , -1, Cancelled, , Cancelled)"},"metadata":{}}],"execution_count":1,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"74f1155a-a3f7-4abd-b8b4-e0901fab839e"},{"cell_type":"markdown","source":["## Configuration"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5c6ce8e0-decc-4110-88ab-74eb1d6b9613"},{"cell_type":"markdown","source":["### Set External parameters"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e33d5f25-3aa0-4ee3-b78e-114d64ceed92"},{"cell_type":"code","source":["# Keep Only External parameters in this cell.\n","onelake_name = \"onelake\"\n","workspace_name = \"ws-mdw\"\n","lakehouse_name = \"LH_Taxi\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":null,"statement_ids":null,"state":"waiting","livy_statement_state":null,"session_id":null,"normalized_state":"waiting","queued_time":"2024-10-17T13:34:04.157273Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"0c1c142e-6233-4551-924e-e4bce124bc02"},"text/plain":"StatementMeta(, , , Waiting, , Waiting)"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"tags":["parameters"],"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"03075e96-b60f-4561-92f2-d9c14ae13916"},{"cell_type":"code","source":["print(f\"{onelake_name = }\")\n","print(f\"{workspace_name = }\")\n","print(f\"{lakehouse_name = }\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":null,"statement_ids":null,"state":"waiting","livy_statement_state":null,"session_id":null,"normalized_state":"waiting","queued_time":"2024-10-17T13:34:04.1579994Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"f5e619c9-8a0d-44c4-9b5f-6763d99abba1"},"text/plain":"StatementMeta(, , , Waiting, , Waiting)"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"15993285-991e-480f-906d-276a0c5399f0"},{"cell_type":"markdown","source":["### Set local parameters"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"aeab0b3a-f6f7-479a-a95b-aa4572ba1ed7"},{"cell_type":"code","source":["# Complete paths - This way we are independent of local workspace - we can connect to any workspace and any lake house as long we have the proper access. \n","lakehouse_table_name = \"tbl_city_safety_data\"\n","cities = (\"Boston\", \"Chicago\", \"NewYorkCity\", \"Seattle\", \"SanFrancisco\") # (\"Boston\", )\n","\n","print(f\"{workspace_name = }\")\n","print(f\"{cities = }\")\n","print(f\"{lakehouse_table_name = }\")\n","\n","# Microsoft Open dataset - Safety data - Ref: https://learn.microsoft.com/en-us/azure/open-datasets/dataset-new-york-city-safety?tabs=pyspark\n","# Azure storage access info  \n","blob_account_name = \"azureopendatastorage\"\n","blob_container_name = \"citydatacontainer\"\n","blob_relative_path = \"Safety/Release/\"\n","blob_sas_token = r\"\"\n","\n","onelake_path = f\"abfss://{workspace_name}@{onelake_name}.dfs.fabric.microsoft.com/{lakehouse_name}.lakehouse\"\n","onelake_file_path = f\"{onelake_path}/Files\"\n","onelake_table_path = f\"{onelake_path}/Tables\"\n","\n","# Allow Spark remote read\n","wasbs_path = f\"wasbs://{blob_container_name}@{blob_account_name}.blob.core.windows.net/{blob_relative_path}\"\n","spark.conf.set( f\"fs.azure.sas.{blob_container_name}.{blob_account_name}.blob.core.windows.net\", blob_sas_token)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":null,"statement_ids":null,"state":"waiting","livy_statement_state":null,"session_id":null,"normalized_state":"waiting","queued_time":"2024-10-17T13:34:04.1586515Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"4fdb160c-81f4-4722-a8b9-2d7a128bab04"},"text/plain":"StatementMeta(, , , Waiting, , Waiting)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d033bce7-f2f1-45d0-8124-6b02a2627f76"},{"cell_type":"code","source":["# Check onelake existence - otherwise abort notebook execution\n","error_message = f\"Specfied lakehouse table path {onelake_table_path} doesn't exist. Ensure onelake={onelake_name}, workspace={workspace_name} and lakehouse={lakehouse_name} exist.\"\n","try:\n","    if not(mssparkutils.fs.exists(onelake_table_path)):\n","        raise ValueError(\"Encountered error while checking for Lakehouse table path specified.\")\n","except Exception as e:\n","    print(f\"Error message: {e}\")\n","    # no further execution but Session is still active\n","    mssparkutils.notebook.exit(error_message)\n","else:\n","    print(f\"Target table path: {onelake_table_path} is valid and exists.\")\n","    print(\"Listing source data contents to check connectivity\")\n","    print(mssparkutils.fs.ls(wasbs_path))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":null,"statement_ids":null,"state":"waiting","livy_statement_state":null,"session_id":null,"normalized_state":"waiting","queued_time":"2024-10-17T13:34:04.1592701Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"4e0ae50f-4e2d-4f05-acf9-4ef07b9d931b"},"text/plain":"StatementMeta(, , , Waiting, , Waiting)"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"177e3c18-ef40-4acc-984e-eae7aa132275"},{"cell_type":"markdown","source":["## Create data extraction and load functions"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4a87eda6-c9a5-433e-a449-32c5bd2ec10d"},{"cell_type":"code","source":["def identify_table_load_mode(table_name: str) -> bool:\n","\n","    # Not so preferred option - works when we have a default lakehouse attached\n","    # load_mode = \"append\" if spark.catalog.tableExists(table_name) else \"overwrite\"\n","\n","    # Preferred option - Assuming default lakehouse is not set, checking based on the delta path\n","    load_mode = \"append\" if DeltaTable.isDeltaTable(spark, f\"{onelake_table_path}/{table_name}\") else \"overwrite\"\n","    \n","    return  load_mode\n","\n","def delete_delta_table(table_name: str) -> bool:\n","\n","    delta_table_path = f\"{onelake_table_path}/{table_name}\"\n","\n","    if mssparkutils.fs.exists(delta_table_path):\n","        print(f\"Attempting to delete exisitng delta table with {delta_table_path = }....\")\n","\n","        try:\n","            mssparkutils.fs.rm(dir=delta_table_path, recurse=True)   \n","        except Exception as e:\n","            print(f\"Deletion failed with the error:\\n===={e}\\n=====\")\n","            raise\n","        else:\n","            print(f\"Deleted exisitng delta table: {table_name}.\")\n","    else:\n","        print(f\"The specified delta table doesn't exist. No need for deletion.\")\n","\n","def transform_data(city: str, data_frame: object) -> object:\n","\n","    # Need timezone to convert to UTC\n","    if city in (\"Boston\", \"NewYorkCity\"):\n","        timezone = \"America/New_York\"\n","    elif city in (\"Seattle\", \"SanFrancisco\"):\n","        timezone = \"America/Los_Angeles\"\n","    else:\n","        timezone = \"America/Chicago\"\n","\n","    data_frame = data_frame\\\n","        .withColumn(\"dateTimeUTC\", to_utc_timestamp(data_frame.dateTime, timezone)) \\\n","        .withColumn(\"City\", lit(city))\n","\n","    return data_frame\n","\n","def etl_steps(table_name: str, cleanup: Optional[bool] = True) -> None:\n","\n","    # Optionally delete existing contents\n","    delta_table_path = f\"{onelake_table_path}/{table_name}\"\n","    if cleanup:\n","        delete_delta_table(table_name)\n","        print(f\"A new delta table '{table_name}' will be created with {delta_table_path = }\")\n","    else:\n","        print(\"No request for cleanup. Proceeding to ETL steps.\")\n","    \n","    for city in cities:\n","        print(f\"ETL started for {city = }.\")\n","\n","        print(f\"\\t Data Extraction in progress.\")\n","        city_calls_data_path = f\"{wasbs_path}/city={city}\"\n","        city_calls_df = spark.read.parquet(city_calls_data_path)\n","\n","        print(f\"\\t Read {city_calls_df.count()} records for {city = }.\")\n","        print(f\"\\t Data transformation in progress.\")\n","        city_calls_df = transform_data(city, city_calls_df)\n","\n","        delta_mode = identify_table_load_mode(table_name)\n","        print(f\"\\t Data loading in inprogress using {delta_mode} mode.\")\n","        city_calls_df.write.format(\"delta\").mode(delta_mode).save(delta_table_path) \n","    \n","    print(f\"\\n=====\\nCity safety data is loaded into {table_name =} for {cities =}\\n=====\")\n","\n","    return None\n","\n","def gather_city_level_metrics(table_name: str) -> None:\n","\n","    delta_table = spark.read.format(\"delta\").load(f\"{onelake_table_path}/{table_name}\")\n","    city_metrics = delta_table.groupBy(\"city\").agg(  \n","        count(\"*\").alias(\"count\")  \n","        # avg(\"metric1\").alias(\"avg_metric1\"),  \n","        # max(\"metric2\").alias(\"max_metric2\"),  \n","        # min(\"metric3\").alias(\"min_metric3\"),  \n","        # sum(\"metric4\").alias(\"sum_metric4\")  \n","    )  \n","  \n","    display(city_metrics)\n","\n","    return None\n","\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":null,"statement_ids":null,"state":"waiting","livy_statement_state":null,"session_id":null,"normalized_state":"waiting","queued_time":"2024-10-17T13:34:04.1599449Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"f0d98141-8b3c-4866-99cd-9664fe4eb1dd"},"text/plain":"StatementMeta(, , , Waiting, , Waiting)"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7e8556ac-447b-4e06-8547-b21c34708df1"},{"cell_type":"markdown","source":["## Read Microsoft Open data sets and load the target table"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b374c6d8-8dcd-4131-a86d-7743cf01b823"},{"cell_type":"code","source":["# main function\n","try:\n","    etl_steps(table_name=lakehouse_table_name, cleanup=True)\n","except Exception as e:\n","    print(f\"ETL step failed with error {e}\")\n","    raise\n","else:\n","    gather_city_level_metrics(table_name=lakehouse_table_name)\n","finally:\n","    print(\"City safety processing is complete.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":null,"statement_ids":null,"state":"waiting","livy_statement_state":null,"session_id":null,"normalized_state":"waiting","queued_time":"2024-10-17T13:34:04.1606202Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"dbf24435-059c-4073-88c2-a4a87e9f78bd"},"text/plain":"StatementMeta(, , , Waiting, , Waiting)"},"metadata":{}}],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"72227768-dd8c-4b6b-816b-fce486e8ed0d"},{"cell_type":"markdown","source":["## Visualize data"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"413dd708-f74a-49e2-8283-39e782a9fd51"},{"cell_type":"code","source":["# WIP"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":null,"statement_ids":null,"state":"waiting","livy_statement_state":null,"session_id":null,"normalized_state":"waiting","queued_time":"2024-10-17T13:34:04.1612887Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"957ed165-692c-422f-95e9-f2fed5bf2afd"},"text/plain":"StatementMeta(, , , Waiting, , Waiting)"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b4ac6fb8-864b-4157-a3d0-e2dfad5d102a"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"synapse_widget":{"state":{},"version":"0.1"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"51ce4d1e-ef92-4f1c-8680-a4eeb8980d92"},{"id":"14040c81-4a29-4c2b-b237-8906d182e815"}],"default_lakehouse":"14040c81-4a29-4c2b-b237-8906d182e815","default_lakehouse_name":"lh_mdw5","default_lakehouse_workspace_id":"c0910b79-037c-4242-9e20-5d9c610f16ab"},"environment":{}}},"notebookName":"nb-mdw5"}